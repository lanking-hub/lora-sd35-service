import os
import torch
import uuid
from datetime import datetime
from diffusers import StableDiffusion3Pipeline
import warnings
from typing import Tuple, Dict, Any
from utils import upload_file_to_oss, get_oss_config_from_env, generate_title_qwen

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings("ignore")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# è®¾ç½®ä¸´æ—¶æ–‡ä»¶ç›®å½•
if os.name == 'nt':
    os.environ['TMP'] = 'D:\\temp'
    os.environ['TEMP'] = 'D:\\temp'
else:
    os.environ['TMP'] = '/tmp'
    os.environ['TEMP'] = '/tmp'

# è®¾ç½® Hugging Face é•œåƒ
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# OSS é…ç½®
OSS_MOUNT_POINT = os.getenv("OSS_MOUNT_POINT", "/mnt/oss")
OSS_MODEL_PATH = os.path.join(OSS_MOUNT_POINT, "models", "sd35-medium")

# åŸºç¡€æ¨¡å‹è·¯å¾„
if os.getenv("BASE_MODEL_PATH"):
    BASE_MODEL_PATH = os.getenv("BASE_MODEL_PATH")
    print(f"âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„æ¨¡å‹è·¯å¾„: {BASE_MODEL_PATH}")
elif os.path.exists(OSS_MODEL_PATH):
    BASE_MODEL_PATH = OSS_MODEL_PATH
    print(f"âœ… æ£€æµ‹åˆ° OSS æŒ‚è½½ï¼Œä½¿ç”¨ OSS æ¨¡å‹è·¯å¾„: {BASE_MODEL_PATH}")
else:
    BASE_MODEL_PATH = "stabilityai/stable-diffusion-3.5-medium"
    print(f"âš ï¸  æœªæ£€æµ‹åˆ° OSS æŒ‚è½½ï¼Œå°†ä½¿ç”¨ HuggingFace Hub: {BASE_MODEL_PATH}")

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# å“ç‰Œ LoRA æ˜ å°„
BRAND_LORA_MAP = {
    "zara": os.path.join(PROJECT_ROOT, "zara", "pytorch_lora_weights.safetensors"),
    "hoc": os.path.join(PROJECT_ROOT, "hoc", "pytorch_lora_weights.safetensors"),
    "cos": os.path.join(PROJECT_ROOT, "cos", "pytorch_lora_weights.safetensors"),
    "rl": os.path.join(PROJECT_ROOT, "rl", "pytorch_lora_weights.safetensors"),
    "lulu": os.path.join(PROJECT_ROOT, "lulu", "pytorch_lora_weights.safetensors"),
}

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
_pipe: Any = None


def load_pipeline():
    """å»¶è¿ŸåŠ è½½ pipeline"""
    global _pipe
    if _pipe is not None:
        return _pipe

    print(f"ğŸ“¦ æ­£åœ¨åŠ è½½ SD3.5 æ¨¡å‹...")
    print(f"   æ¨¡å‹è·¯å¾„: {BASE_MODEL_PATH}")
    print(f"   è®¾å¤‡: {DEVICE}")

    try:
        print("   æ­£åœ¨åŠ è½½æ¨¡å‹ç»„ä»¶ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")

        if DEVICE == "cuda":
            print("   âœ… ä½¿ç”¨ GPU æ¨¡å¼ï¼ˆå¿«é€Ÿï¼‰")
            dtype = torch.float16
        else:
            print("   âš ï¸  ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆè¾ƒæ…¢ï¼Œçº¦ 30 åˆ†é’Ÿ/å¼ ï¼‰")
            dtype = torch.float32

        is_local_path = (
            os.path.exists(BASE_MODEL_PATH) or
            BASE_MODEL_PATH.startswith("/") or
            BASE_MODEL_PATH.startswith("./") or
            BASE_MODEL_PATH.startswith("../") or
            (len(BASE_MODEL_PATH) > 1 and BASE_MODEL_PATH[1] == ':')
        )

        load_kwargs = {
            "torch_dtype": dtype,
            "use_safetensors": True,
            "low_cpu_mem_usage": True,
        }

        if is_local_path:
            load_kwargs["local_files_only"] = True
            print(f"   ğŸ”’ ä½¿ç”¨æœ¬åœ°æ–‡ä»¶æ¨¡å¼ (local_files_only=True)")

        _pipe = StableDiffusion3Pipeline.from_pretrained(
            BASE_MODEL_PATH,
            **load_kwargs
        )

        # ç›´æ¥åŠ è½½åˆ°GPU
        if DEVICE == "cuda":
            print("   ç›´æ¥åŠ è½½åˆ°GPUï¼ˆä¸ä½¿ç”¨CPU offloadï¼‰  ")
            _pipe = _pipe.to(DEVICE)
        else:
            _pipe = _pipe.to(DEVICE)

        _pipe.enable_attention_slicing()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

    except Exception as e:
        import traceback
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

    return _pipe


def validate_request(event: Dict[str, Any]) -> Tuple[str, str]:
    """éªŒè¯è¯·æ±‚æ•°æ®"""
    brand = event.get("brand", "").lower()
    prompt = event.get("prompt", "")

    if not brand:
        raise ValueError("ç¼ºå°‘ 'brand' å‚æ•°")

    if brand not in BRAND_LORA_MAP:
        raise ValueError(f"ä¸æ”¯æŒçš„å“ç‰Œ: {brand}ï¼Œæ”¯æŒçš„å“ç‰Œ: {', '.join(BRAND_LORA_MAP.keys())}")

    if not prompt:
        raise ValueError("ç¼ºå°‘ 'prompt' å‚æ•°")

    return brand, prompt


def translate_prompt(prompt: str) -> str:
    """ç¿»è¯‘ä¸­æ–‡æç¤ºè¯åˆ°è‹±æ–‡"""
    try:
        from openai import OpenAI
        api_key = os.getenv("QWEN_API_KEY")
        if not api_key:
            print("âš ï¸  æœªé…ç½® QWEN_API_KEYï¼Œè·³è¿‡ç¿»è¯‘")
            return prompt

        client = OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

        print(f"ğŸŒ æ­£åœ¨ç¿»è¯‘æç¤ºè¯...")
        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘ï¼Œå°†ä¸­æ–‡ç¿»è¯‘æˆé€‚åˆ AI ç»˜ç”»çš„è‹±æ–‡æç¤ºè¯ã€‚åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚"},
                {"role": "user", "content": prompt}
            ]
        )

        translated = completion.choices[0].message.content.strip()
        print(f"   ç¿»è¯‘ç»“æœ: {translated}")
        return translated

    except Exception as e:
        print(f"âš ï¸  ç¿»è¯‘å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸæç¤ºè¯")
        return prompt


def generate_title(english_prompt: str) -> str:
    """ç”Ÿæˆä¸­æ–‡äº§å“æ ‡é¢˜"""
    try:
        result = generate_title_qwen(english_prompt)
        # generate_title_qwen è¿”å›å…ƒç»„ (è‹±æ–‡æç¤ºè¯, ä¸­æ–‡æ ‡é¢˜)
        # éœ€è¦æå–ç¬¬äºŒä¸ªå…ƒç´ ï¼ˆä¸­æ–‡æ ‡é¢˜ï¼‰
        if isinstance(result, tuple) and len(result) > 1:
            title = result[1]
        else:
            title = result
        
        if len(title) > 15:
            title = title[:15]
        return title
    except Exception as e:
        print(f"âš ï¸  æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {e}")
        return "AIç”Ÿæˆå›¾åƒ"


def generate_image(brand: str, prompt: str) -> str:
    """ç”Ÿæˆå›¾åƒ"""
    print(f"\n{'='*60}")
    print(f"ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾åƒ")
    print(f"{'='*60}")

    try:
        pipe = load_pipeline()

        lora_path = BRAND_LORA_MAP[brand]
        print(f"ğŸ“Œ LoRA æƒé‡: {lora_path}")

        if not os.path.exists(lora_path):
            raise FileNotFoundError(f"LoRA æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")

        # ğŸ”§ æ™ºèƒ½LoRAç®¡ç†ï¼šæ£€æŸ¥adapteræ˜¯å¦å·²åŠ è½½
        print(f"ğŸ” æ£€æŸ¥ LoRA adapter çŠ¶æ€...")
        
        # è·å–å½“å‰å·²åŠ è½½çš„æ‰€æœ‰adapters
        if hasattr(pipe, 'get_active_adapters'):
            active_adapters = pipe.get_active_adapters()
        else:
            active_adapters = []
        
        print(f"   å½“å‰æ¿€æ´»çš„adapters: {active_adapters}")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åŠ è½½æ–°adapter
        if brand in active_adapters:
            # å·²åŠ è½½ï¼Œç›´æ¥æ¿€æ´»ä½¿ç”¨
            print(f"âœ… LoRA '{brand}' å·²åŠ è½½ï¼Œç›´æ¥ä½¿ç”¨")
            pipe.set_adapters([brand])
        else:
            # å°è¯•åŠ è½½æ–°adapter
            try:
                pipe.load_lora_weights(lora_path, adapter_name=brand)
                pipe.set_adapters([brand])
                print(f"âœ… æˆåŠŸåŠ è½½ LoRA: {brand}")
            except ValueError as e:
                if "already in use" in str(e):
                    # å·²å­˜åœ¨ä½†æœªæ¿€æ´»ï¼Œç›´æ¥æ¿€æ´»
                    print(f"âœ… LoRA '{brand}' å·²å­˜åœ¨ï¼Œæ¿€æ´»ä½¿ç”¨")
                    pipe.set_adapters([brand])
                else:
                    raise e

        combined_prompt = f"{prompt}, high quality, professional photography, fashion photography"

        print(f"ğŸ“ æç¤ºè¯: {combined_prompt}")
        print(f"â³ å¼€å§‹ç”Ÿæˆ...ï¼ˆè¿™å¯èƒ½éœ€è¦ 20-40 ç§’ï¼‰")

        with torch.no_grad():
            result = pipe(
                prompt=combined_prompt,
                num_inference_steps=25,
                guidance_scale=7.5,
                height=1024,
                width=1024,
            )

        os.makedirs("/tmp/images", exist_ok=True)
        filename = f"{uuid.uuid4()}.jpg"
        image_path = os.path.join("/tmp/images", filename)
        result.images[0].save(image_path)

        print(f"âœ… å›¾åƒå·²ä¿å­˜: {image_path}")
        return image_path

    except Exception as e:
        import traceback
        print(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
        traceback.print_exc()
        raise RuntimeError(f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")


def handler(event: Dict[str, Any], context: Any = None) -> Dict[str, Any]:
    """å‡½æ•°è®¡ç®—å…¥å£"""
    try:
        print(f"\n{'='*60}")
        print(f"æ”¶åˆ°æ–°çš„å›¾åƒç”Ÿæˆè¯·æ±‚")
        print(f"{'='*60}")
        print(f"ğŸ“‹ è¯·æ±‚å‚æ•°:")
        print(f"   å“ç‰Œ: {event.get('brand', '')}")
        print(f"   æç¤ºè¯é•¿åº¦: {len(event.get('prompt', ''))} å­—ç¬¦")

        # éªŒè¯è¯·æ±‚
        brand, prompt = validate_request(event)

        print(f"\nğŸ” LoRA é…ç½®:")
        print(f"   è·¯å¾„: {BRAND_LORA_MAP[brand]}")
        print(f"   æ–‡ä»¶å­˜åœ¨: {os.path.exists(BRAND_LORA_MAP[brand])}")

        # ç¿»è¯‘æç¤ºè¯
        english_prompt = translate_prompt(prompt)

        # ç”Ÿæˆå›¾åƒ
        image_path = generate_image(brand, english_prompt)

        # ä¸Šä¼ åˆ° OSS
        print(f"\nâ˜ï¸  ä¸Šä¼ åˆ° OSS...")
        oss_config = get_oss_config_from_env()
        image_url = upload_file_to_oss(image_path, oss_config)

        # ç”Ÿæˆæ ‡é¢˜
        title = generate_title(english_prompt)
        print(f"ğŸ“ æ ‡é¢˜: {title}")

        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"   å›¾ç‰‡ URL: {image_url}")

        return {
            "success": True,
            "image_url": image_url,
            "title": title
        }

    except ValueError as e:
        # å‚æ•°éªŒè¯é”™è¯¯
        print(f"\nâŒ å‚æ•°é”™è¯¯: {e}")
        return {
            "success": False,
            "url": None,
            "title": None,
            "error": str(e)
        }

    except Exception as e:
        # å…¶ä»–é”™è¯¯
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "url": None,
            "title": None,
            "error": str(e)
        }


# ========== FastAPI å…¼å®¹å±‚ ==========
def main(event, context=None):
    """FastAPI app.py å…¼å®¹çš„å…¥å£å‡½æ•°
    
    Args:
        event: äº‹ä»¶å­—å…¸ï¼ŒåŒ…å« brand å’Œ prompt
        context: ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        (success, result): å…ƒç»„æ ¼å¼ï¼Œå…¼å®¹ app.py è°ƒç”¨
    """
    result = handler(event, context)
    
    if result.get("success"):
        return True, {
            "url": result["image_url"],
            "title": result["title"]
        }
    else:
        return False, result.get("error", "Unknown error")


if __name__ == "__main__":
    # æœ¬åœ°æµ‹è¯•
    import json
    test_event = {
        "brand": "zara",
        "prompt": "ä¸€ä»¶ä¼˜é›…çš„çº¢è‰²æ™šç¤¼æœï¼Œé€‚åˆæ­£å¼åœºåˆ"
    }
    result = handler(test_event)
    print(f"\næµ‹è¯•ç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))
