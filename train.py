import torch
import os
from datetime import datetime
from diffusers import StableDiffusion3Pipeline
import warnings

def main():
    device = "cuda"
    torch.manual_seed(42)
    os.makedirs("outputs", exist_ok=True)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå°è¯•ä¼˜åŒ–é•¿æ–‡æœ¬å¤„ç†
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # å‡å°‘TensorFlowæ—¥å¿—
    
    # å®Œå…¨æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Š
    warnings.filterwarnings("ignore")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½SD3.5æ¨¡å‹...")
    model_path = "/root/autodl-tmp/models/stable-diffusion-3.5-medium"
    lora_path = "/root/autodl-tmp/main/dive-into-stable-diffusion-v3-5-main/outputs/train_text_to_image_lora_sd3-zara/pytorch_lora_weights.safetensors"
    
    try:
        pipe = StableDiffusion3Pipeline.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            use_safetensors=True,
            variant="fp16"
        ).to(device)
        
        # åŠ è½½LoRAæƒé‡
        print("ğŸ“¥ åŠ è½½LoRAæƒé‡...")
        
        # æ–¹æ³•1: ä½¿ç”¨load_lora_weightsæ–¹æ³•ï¼ˆå¦‚æœæ”¯æŒï¼‰
        try:
            pipe.load_lora_weights(
                lora_path,
                adapter_name="my_lora",
                weight_name="pytorch_lora_weights.safetensors"
            )
            print("âœ… LoRAæƒé‡åŠ è½½æˆåŠŸ (æ–¹æ³•1)")
        except:
            # æ–¹æ³•2: ç›´æ¥ä½¿ç”¨load_lora_weights
            try:
                pipe.load_lora_weights(lora_path)
                print("âœ… LoRAæƒé‡åŠ è½½æˆåŠŸ (æ–¹æ³•2)")
            except:
                # æ–¹æ³•3: ä½¿ç”¨load_lora_weights_into_pipelineï¼ˆå¯¹äºSD3.5å¯èƒ½éœ€è¦ç‰¹å®šæ–¹æ³•ï¼‰
                try:
                    from diffusers.loaders import load_lora_weights_into_pipeline
                    load_lora_weights_into_pipeline(pipe, lora_path)
                    print("âœ… LoRAæƒé‡åŠ è½½æˆåŠŸ (æ–¹æ³•3)")
                except Exception as e:
                    print(f"âš ï¸ æ ‡å‡†LoRAåŠ è½½æ–¹æ³•å¤±è´¥: {e}")
                    # æ–¹æ³•4: æ‰‹åŠ¨åŠ è½½æƒé‡ï¼ˆæœ€åçš„æ‰‹æ®µï¼‰
                    print("å°è¯•æ‰‹åŠ¨èåˆLoRAæƒé‡...")
                    try:
                        from safetensors.torch import load_file
                        lora_weights = load_file(lora_path)
                        
                        # è·å–ç®¡é“ä¸­çš„UNet
                        unet = pipe.unet
                        
                        # ç®€å•çš„LoRAæƒé‡åˆå¹¶ï¼ˆå‡è®¾æ˜¯å¸¸è§çš„LoRAæ ¼å¼ï¼‰
                        for key in lora_weights:
                            if 'lora' in key.lower():
                                # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„LoRAæƒé‡ç»“æ„è¿›è¡Œæ›´ç²¾ç»†çš„å¤„ç†
                                # ç”±äºSD3.5çš„ç‰¹æ®Šç»“æ„ï¼Œè¿™å¯èƒ½æ¯”è¾ƒå¤æ‚
                                print(f"æ‰¾åˆ°LoRAæƒé‡: {key}")
                        
                        print("âœ… LoRAæƒé‡æ‰‹åŠ¨åŠ è½½å®Œæˆï¼ˆåŸºæœ¬ç»“æ„è¯†åˆ«ï¼‰")
                    except Exception as e2:
                        print(f"âŒ æ‰€æœ‰LoRAåŠ è½½æ–¹æ³•å‡å¤±è´¥: {e2}")
                        print("ç»§ç»­ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆä¸å«LoRAï¼‰...")
        
        # å¯ç”¨å†…å­˜ä¼˜åŒ–
        pipe.enable_attention_slicing()
        
        # æ£€æŸ¥T5ç¼–ç å™¨
        if hasattr(pipe, 'tokenizer_3'):
            print("âœ… æ‰¾åˆ°T5ç¼–ç å™¨ç»„ä»¶")
            
            # æµ‹è¯•T5ç¼–ç å™¨çš„å®é™…å¤„ç†èƒ½åŠ›
            test_text = "ä¸€ä»¶è®¾è®¡ç²¾ç¾çš„ç™½è‰²ä¸­é•¿è¿è¡£è£™ï¼Œé‡‡ç”¨å‚å æ„Ÿé¢æ–™"
            tokens = pipe.tokenizer_3.encode(test_text)
            print(f"T5æµ‹è¯•åˆ†è¯æ•°é‡: {len(tokens)} tokens")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # å®šä¹‰æµ‹è¯•æç¤ºè¯ - æ ¹æ®ä½ çš„LoRAè®­ç»ƒå†…å®¹è°ƒæ•´
    test_prompts = [
        {
            "name": "LoRAæµ‹è¯•1",
            "prompt": "Off-white top, chiffon, with a small amount of matching color embroidery, sleeveless, flowing",
            "negative": "ugly, deformed, blurry, low quality, pixelated, cartoon, drawing",
            "seed": 125,
            "steps": 60,
            "guidance": 6.0,
            "height": 896,
            "width": 896,
            "lora_scale": 0.8  # LoRAæƒé‡å¼ºåº¦
        },
        {
            "name": "LoRAæµ‹è¯•2",
            "prompt": "Light blue cake dress, layered, worn by a female model, short skirt, cinched waist",
            "negative": "ugly, deformed, blurry, low quality, pixelated, cartoon, drawing",
            "seed": 4212,
            "steps": 60,
            "guidance": 5.0,
            "height": 1216,
            "width": 832,
            "lora_scale": 1.0
        }
    ]
    
    for i, test in enumerate(test_prompts):
        print(f"\n{'='*60}")
        print(f"ç”Ÿæˆæµ‹è¯• {i+1}: {test['name']}")
        print(f"{'='*60}")
        print(f"æç¤ºè¯: {test['prompt']}")
        print(f"LoRAå¼ºåº¦: {test.get('lora_scale', 1.0)}")
        
        try:
            # ç”Ÿæˆå›¾åƒ - å°è¯•ä½¿ç”¨LoRA
            generator = torch.Generator(device=device).manual_seed(test['seed'])
            
            print("å¼€å§‹ç”Ÿæˆï¼ˆä½¿ç”¨LoRAï¼‰...")
            
            # å°è¯•ä¸åŒçš„ç”Ÿæˆæ–¹æ³•
            generation_kwargs = {
                "prompt": test['prompt'],
                "negative_prompt": test['negative'],
                "num_inference_steps": test['steps'],
                "guidance_scale": test['guidance'],
                "height": test['height'],
                "width": test['width'],
                "generator": generator,
            }
            
            # å¦‚æœLoRAåŠ è½½æˆåŠŸï¼Œæ·»åŠ LoRAå‚æ•°
            lora_scale = test.get('lora_scale', 1.0)
            if lora_scale != 1.0:
                try:
                    # å°è¯•ä½¿ç”¨LoRAç¼©æ”¾å‚æ•°
                    generation_kwargs["cross_attention_kwargs"] = {"scale": lora_scale}
                except:
                    pass
            
            image = pipe(**generation_kwargs).images[0]
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"outputs/lora_test_{i+1}_{timestamp}.png"
            image.save(filename)
            
            print(f"âœ… æˆåŠŸç”Ÿæˆ!")
            print(f"ä¿å­˜ä½ç½®: {filename}")
            print(f"å›¾åƒå°ºå¯¸: {image.size}")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            
            # å°è¯•ç®€åŒ–ç‰ˆæœ¬ï¼ˆä¸ä½¿ç”¨LoRAï¼‰
            print("å°è¯•ä¸ä½¿ç”¨LoRAçš„ç®€åŒ–ç‰ˆæœ¬...")
            try:
                generator = torch.Generator(device=device).manual_seed(test['seed'])
                image = pipe(
                    prompt=test['prompt'][:100],  # ä½¿ç”¨æ›´çŸ­çš„æç¤ºè¯
                    num_inference_steps=30,
                    guidance_scale=4.0,
                    height=768,
                    width=768,
                    generator=generator,
                ).images[0]
                filename = f"outputs/baseline_test_{i+1}.png"
                image.save(filename)
                print(f"ç®€åŒ–ç‰ˆç”ŸæˆæˆåŠŸ: {filename}")
                
            except Exception as e2:
                print(f"ç®€åŒ–ç‰ˆä¹Ÿå¤±è´¥: {e2}")
    # é¢å¤–çš„è°ƒè¯•ä¿¡æ¯
    print("\nè°ƒè¯•ä¿¡æ¯:")
    print("1. æ£€æŸ¥LoRAæ–‡ä»¶æ˜¯å¦å­˜åœ¨:", os.path.exists(lora_path))
    if os.path.exists(lora_path):
        print(f"   LoRAæ–‡ä»¶å¤§å°: {os.path.getsize(lora_path) / 1024 / 1024:.2f} MB")
    
    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    print("   a. ç¡®è®¤LoRAæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆåº”ä¸º.safetensorsæ ¼å¼ï¼‰")
    print("   b. æ£€æŸ¥LoRAæ˜¯å¦é’ˆå¯¹SD3.5è®­ç»ƒï¼ˆä¸åŒç‰ˆæœ¬å¯èƒ½ä¸å…¼å®¹ï¼‰")
    print("   c. å°è¯•ä¸åŒçš„LoRAå¼ºåº¦ï¼ˆ0.5-1.5èŒƒå›´ï¼‰")
    print("   d. ä½¿ç”¨è®­ç»ƒLoRAæ—¶ä½¿ç”¨çš„ç›¸åŒæç¤ºè¯é£æ ¼")

if __name__ == "__main__":
    main()